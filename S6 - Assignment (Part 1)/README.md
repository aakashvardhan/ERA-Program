# Neural Network Backpropogation

## Introduction

- Backpropogation is the most fundamental building block of a neural network. It is used to calculate the gradient of a loss function with respect to the weights of the network, "computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule"[cited: https://en.wikipedia.org/wiki/Backpropagation]



## Tutorial

- $i_1$ and $i_2$ --> Input layer neurons
- $h_1$ and $h_2$ --> Hidden layer neurons
- 